<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>
            Operating System Concepts
        </title>
        <link rel="stylesheet" href="./style.css"/>
    </head>
    <body>
        <nav id="navbar">
            <header id="title">Operating System</header>
            <ul>
              <li><a class="nav-link" href="#overview">Overview</a></li>
              <li>
                <a class="nav-link" href="#processconcept"
                  >Process Concept</a
                >
              </li>
              <li>
                <a class="nav-link" href="#processscheduling">Process Scheduling</a>
              </li>
              <li><a class="nav-link" href="#threadconcept">Thread Concept</a></li>
              <li><a class="nav-link" href="#synchronisation">Synchronisation</a></li>
              <li>
                <a class="nav-link" href="#deadlock">Deadlock</a>
              </li>
              <li><a class="nav-link" href="#memorymaanagementstrategy">Memory Management Strategy</a></li>
              <li><a class="nav-link" href="#virtualmemorymanagement">Virtual Memory Management</a></li>
            </ul>
          </nav>
          <main id="main-doc">
            <section class="main-section" id="overview">
              <header>Overview</header>
              <article>
                <p>
                 <b>Operating System</b>, is a program that manages computer hardware. It provides a basis for application programs
                 and acts as an interface between computer user and the computer hardware.
                </p>
          
                <p>
                 There are different operating system which accomplish these tasks in different way.For eg 
                 <b>Mainframe</b> operating system are designed for the optimal utilisation of hardware , <b>PC</b> operating system
                 are designed for supporting complex games, applications and to increase efficiency and <b>mobile </b>operating system
                 provide an environment where user can easily interface with the computer to execute programs.

                </p>
                <h2>Services Provided By An Operating System</h2>
                <ul>
                  <li>
                    <h3>Interface between user and hardware</h3>
                    <p>For eg : In a C program we write printf if there would be no OS we need to specify the code 
                      to interact with the hardware also, but with os when we will write printf OS will issue a <a href="#">system call</a>
                      write for it.
                    </p>
                    <li>
                      <h3>Resource Allocator</h3>
                      <p>It assignes processes to particular resources(device,memory,I/O,files).
                        If the resource is <b>unsharable</b> it will allocate resource to 1 process at a time but if the resource is <b>sharable</b> it will allocate resources to different processes 
                        simultaneously.
                    </li>
                    <li>
                      <h3>Manager</h3>
                      <p>It manages memory , processes , files, security etc. It keeps track of which resources are allocated
                        to which process and which are free.
                      </p>
                    </li>
                    </p>
                  </li>
                </ul>
                <h2>Types of Operating System</h2>
                <ul>
                  <li>
                    <h3>Batch Operating System</h3>
                    <p>As the name suggests here the computer operator sorts the similar kind of jobs together in a batch and will allocate them. 
                      It does not directly interact with the computer. This type of OS was generally used when we use a single mainframe computer and everyone assign their 
                      job to that computer only.
                    </p>
                    <table>
                      <tr>
                        <th>Advantages</th>
                        <th>Disadvantages</th>
                      </tr>
                      <tr>
                        <td>Multiple users can share the batch systems.</td>
                        <td>Costly</td>
                      </tr>
                      <tr>
                        <td>Easy to manage large work</td>
                        <td>Hard to debug</td>
                      </tr>
                      <tr>
                        <td>Eg : Bank System , Payroll Statements etc.</td>
                        <td>The other jobs will have to wait for unknown time if any job fails.</td>
                      </tr>
                    </table>
                  </li>
                  <li>
                    <h3>Multiprogramming OS</h3>
                    <p>In the multi-programming system, one or multiple programs can be loaded into its main memory for getting to execute. Main objective of multiprogramming is to manage entire resources of the system. Multiprogramming operating system has ability to execute multiple programs with using of only one processor machine . One example is User can use MS-Excel , download apps, transfer data from one point to another point, Firefox or Google Chrome browser, and more at a same time.
                      When the process has gone to I/O CPU can take and execute other jobs and processes.
                    </p>
                    <table>
                      <tr>
                        <th>
                          Advantages
                        </th>
                        <th>
                          Disadvantages
                        </th>
                      </tr>
                      <tr>
                        <td>
                          Cpu is not idle so more efficient as resources are used nicely.
                        </td>
                         <td>
                           Difficult to handle because of complex schedule handling.
                         </td>
                      </tr>
                      <tr>
                        <td>Supports multiple users simultaneously</td>
                        <td>
                          Tracking all tasks/processes is difficult to handle.
                        </td>
                      </tr>
                      <tr>
                        <td>Short time jobs are completed faster than long time jobs</td>
                        <td>Due to high load of tasks, long time jobs have to wait long</td>
                      </tr>
                    </table>
                  </li>
                  <li>
                    <h3>Multitasking/TimeSharing OS</h3>
                  <p>Each task is given some time to execute so that all the tasks work smoothly. Each user gets the time of CPU as they use a single system. These systems are also known as Multitasking Systems. The task can be from a single user or different users also. The time that each task gets to execute is called quantum. 
                    After this time interval is over OS switches over to the next task. 
                    For eg if we have three jobs J1,J2,J3. CPU for time quantum of J1 will take J1 after J1's 
                    time quantum is over CPU will start executing J2/J3 even if J1 is complete or not.It is multiprogramming + context switching
                  </p>
                  <table>
                    <tr>
                      <th>
                        Advantages
                      </th>
                      <th>
                        Disadvantages
                      </th>
                    </tr>
                    <tr>
                      <td>
                        Each task gets an equal opportunity
                      </td>
                       <td>
                        Reliability problem
                       </td>
                    </tr>
                    <tr>
                      <td>Fewer chances of duplication of software</td>
                      <td>
                        One must have to take care of the security and integrity of user programs and data
                      </td>
                    </tr>
                    <tr>
                      <td>CPU idle time can be reduced Eg : Unix</td>
                      <td>Data communication problem</td>
                    </tr>
                  </table>
                  </li>
                  <li>
                    <h3>Distributed OS</h3>
                  <p><b>Loosely coupled system</b>Various autonomous interconnected computers communicate with each other using a shared communication network. Independent systems possess their own memory unit and CPU. These are referred to as loosely coupled systems or distributed systems. These system’s processors differ in size and function. The major benefit of working with these types of the operating system is that it is always possible that one user can access the files or software which are not actually present on his system but some other system connected within this network i.e., remote access is enabled within the devices connected in that network. 
                  </p>
                  <table>
                    <tr>
                      <th>
                        Advantages
                      </th>
                      <th>
                        Disadvantages
                      </th>
                    </tr>
                    <tr>
                      <td>
                       Failure of one will not affect other as all are independent.
                      </td>
                       <td>
                        Failure of main will stop the entire communication.
                       </td>
                    </tr>
                    <tr>
                      <td>
                        Since resources are being shared, computation is highly fast and durable
and load on host computer reduces , scalable
                      </td>
                      <td>
                      Language not well defined.
                      </td>
                    </tr>
                    <tr>
                      <td>Delay can be reduced Eg : LOCUS</td>
                      <td>Underlying software is complex and costly.</td>
                    </tr>
                  </table>
                  </li>
                  <li>
                    <h3>Network OS</h3>
                  <p><b>Tighly coupled system</b>These systems run on a server and provide the capability to manage data, users, groups, security, applications, and other networking functions. These types of operating systems allow shared access of files, printers, security, applications, and other networking functions over a small private network. One more important aspect of Network Operating Systems is that all the users are well aware of the underlying configuration, of all other users within the network, their individual connections, etc
                  </p>
                  <table>
                    <tr>
                      <th>
                        Advantages
                      </th>
                      <th>
                        Disadvantages
                      </th>
                    </tr>
                    <tr>
                      <td>
                        Highly stable centralized servers and security concerns are handled through servers
                      </td>
                       <td>
                        Servers are costly
                       </td>
                    </tr>
                    <tr>
                      <td>
                        New technologies and hardware up-gradation are easily integrated into the system
                      </td>
                      <td>
                        User has to depend on a central location for most operations
                      </td>
                    </tr>
                    <tr>
                      <td>Server access is possible remotely from different locations and types of systems Eg : MAC, Windows, LINUX</td>
                      <td>Maintenance and updates are required regularly</td>
                    </tr>
                  </table>
                  </li>
                  <li>
                    <h3>Realtime OS</h3>
                  <p>Here each and every job has its deadlock completing it after will result in loss.
                    <b>Hard Real time</b> time constraint very strict eg:automatic parachutes
                    <b>Soft Real time</b> time constraints not that strict.
                  </p>
                  <table>
                    <tr>
                      <th>
                        Advantages
                      </th>
                      <th>
                        Disadvantages
                      </th>
                    </tr>
                    <tr>
                      <td>
                        maximum consumption , context switching time very less
                      </td>
                       <td>
                         The algorithms are very complex and difficult for the designer to write on
                       </td>
                    </tr>
                    <tr>
                      <td>
                        Focus on running applications and less importance to applications which are in the queue.
                      </td>
                      <td>
                        Very few tasks run at the same time and their concentration is very less on few applications to avoid errors.
                      </td>
                    </tr>
                    <tr>
                      <td>Error Free and best memory management For eg : weapon systems</td>
                      <td>device driver and interrupt signals.</td>
                    </tr>
                  </table>
                  </li>
                </ul>
                <ol>
                  <h2>Differences</h2>
                  <li>
                    <h3>RAM VS ROM</h3>
                    <table>
                      <tr>
                        <th>
                          Random Access Memory
                        </th>
                        <th>
                          Read Only Memory
                        </th>
                      </tr>
                      <tr>
                        <td>
                         Data stored in RAM stays there until the computer is running
                        </td>
                         <td>
                          ROM is used mainly in the start-up process of a modern computer
                         </td>
                      </tr>
                      <tr>
                        <td>
                          RAM types are 1) DRAM 2)SRAM. SDRAM, and DDR
                        </td>
                        <td>
                          ROM types are 1) EPROM 2) EEPROM, 3) PROM, and 4) Mask ROM
                        </td>
                      </tr>
                      <tr>
                        <td>RAM is volatile </td>
                        <td>ROM is non-volatile Memory</td>
                      </tr>
                      <tr>
                        <td>The biggest advantage of RAM is that it does not have any moving parts</td>
                        <td> the biggest advantage of Rom is that it is not lost when power is switched off.</td>
                      </tr>
                    </table>
                    <li>
                      <h3>SRAM VS DRAM</h3>
                      <table>
                        <tr>
                          <th>
                            Static Random Access Memory
                          </th>
                          <th>
                            Dynamic Random Access Memory
                          </th>
                        </tr>
                        <tr>
                          <td>
                            SRAM is a type of semiconductor memory that uses Bistable latching circuitry to store each bit
                          </td>
                           <td>
                            It is a type of RAM which allows you to stores each bit of data in a separate capacitor within a particular integrated circuit.
                           </td>
                        </tr>
                        <tr>
                          <td>
                            Static RAM is mostly used as a cache memory for the processor (CPU).
                          </td>
                          <td>
                            It is a standard computer memory of any modern desktop computer.
                          </td>
                        </tr>
                        <tr>
                          <td>SRAM is faster</td>
                          <td>DRAM is comparitively slower</td>
                        </tr>
                        <tr>
                          <td>It consumes less power</td>
                          <td> Here every bit is stored in a capacitor if bit is 1 means capacitor is charged else discharged</td>
                        </tr>
                      </table>
                  </li>
                  <li>
                    <h3>PROM VS EPROM VS EEPROM</h3>
                    <table>
                      <tr>
                        <th>
                          Programmable ROM
                        </th>
                        <th>
                          Erasable Programmable ROM
                        </th>
                        <th>
                          Electrically Erasable Programmable ROM
                        </th>
                      </tr>
                      <tr>
                        <td>
                         After its creation it can be programmed only once by the users
                        </td>
                         <td>
                         It can be reprogrammed using ultraviolet light
                         </td>
                         <td>
                          It can be reprogrammed by using normal electric voltage.
                          </td>
                      </tr>
                    </table>
                </li>
                <li>
                <h3>Virtualization VS Containerization</h3>
                <table>
                  <tr>
                    <th>
                      Virtualization
                    </th>
                    <th>
                      Containerization
                    </th>
                  </tr>
                  <tr>
                    <td>
                      Virtualization is the technology which can simulate your physical hardware (such as CPU cores, memory, disk)  and represent it as seperate machine
                    </td>
                     <td>
                      Containerization is os-level virtualization. It doesn't simulate the entire physical machine
                     </td>
                  </tr>
                  <tr>
                    <td>
                      It used  Hypervisor to detach the physical machine
                    </td>
                    <td>
                      It used docker engine in case Docker
                    </td>
                  </tr>
                  <tr>
                    <td>It has hardware level isolation so fit is fully secured </td>
                    <td>It has process level isolation</td>
                  </tr>
                  <tr>
                    <td>Heavy weight and not portable</td>
                    <td> Light weight and portable</td>
                  </tr>
                </table>
              </li>
              <li>
                <h3>UEFI VS BIOS</h3>
                Unified Extended Firmware Interface Forum VS Basic Input-Output system
              <p>Both UEFI and BIOS are low-level software that starts when you boot your PC before booting your operating system</p>
              <em>UEFI is a more modern solution, supporting larger hard drives, faster boot times, more security features, and—conveniently—graphics and mouse cursors.</em>
            </li>
            <li>
              <h3>GPT(GUID Partition Table) VS MBR(Master Boot Record)</h3>
              <p>UEFI is able to boot drives of very large size because  UEFI uses the GPT partitioning scheme instead of MBR.</p>
              <p>These are two different ways of storing the partitioning information on a drive</p>
              <em>GPT is replacing MBR because</em>
                <ol>
                  <li>
                    MBR only works with disks up to 2 TB in size. MBR also only supports up to four primary partitions—if you want more, you have to make one of your primary partitions an “extended partition” and create logical partitions inside it.GPT is better as 
                    every partition on your drive has a “globally unique identifier,”.GPT doesn’t suffer from MBR’s limits. GPT-based drives can be much larger and can have unlimited partitions , with size limits and number of partitions dependent on the operating system
                  </li>
                  <li>
                    On an MBR disk, the partitioning and boot data is stored in one place. If this data is overwritten or corrupted, you’re in trouble. In contrast, GPT stores multiple copies of this data across the disk, so it’s much more robust and can recover if the data is corrupted.
                  </li>
                  <li>
                    GPT also stores cyclic redundancy check (CRC) values to check that its data is intact. If the data is corrupted, GPT can notice the problem and attempt to recover the damaged data from another location on the disk. MBR had no way of knowing if its data was corrupted—you’d only see there was a problem when the boot process failed or your drive’s partitions vanished. 
                  </li>
                  <li>
                    <h3>MicroKernel VS Monolithickernel </h3>
                    <table>
                      <tr>
                        <th>
                          MicroKernel(MacOS)
                        </th>
                        <th>
                          Monolithickernel(Linux,Unix)
                        </th>
                      </tr>
                      <tr>
                        <td>
                          In microkernels, the kernel is broken down into separate processes, known as servers. Some of the servers run in kernel space and some run in user-space. All servers are kept separate and run in different address spaces. Servers invoke "services" from each other by sending messages via IPC (Interprocess Communication). This separation has the advantage that if one server fails, other servers can still work efficiently. 
                        </td>
                         <td>
                          Monolithic kernel is a single large process running entirely in a single address space. It is a single static binary file. All kernel services exist and execute in the kernel address space. The kernel can invoke functions directly. Examples of monolithic kernel based OSs: Unix, Linux.
                         </td>
                      </tr>
                    </table>
                </li>
                </ol>
                <em>Why windows kernel is more monolithic and not micro kernel?</em>
                <p> Because the kernel mode protected memory space is shared by the operating system and device driver code.All kernel components live in a common shared address space.It uses hybrid kernel</p>
            </li>
                </ol>
                <h2>Some Important Terms</h2>
                <ul>
                  <li>
                    <h3>
                      Compiler
                    </h3>
                    <p>A compiler is a special program that processes statements written in a particular programming language and turns them into machine language or "code" that a computer's processor uses.</p>
                  </li>
                  <li>
                    <h3>
                      Loader
                    </h3>
                    <p>In a computer operating system , a loader is a component that locates a given program (which can be an application or, in some cases, part of the operating system itself) in offline storage (such as a hard disk ), loads it into main storage (in a personal computer, it's called random access memory ), and gives that program control of the computer (allows it to execute its instruction s).</p>
                  </li>
                  <li>
                    <h3>
                      Assembler
                    </h3>
                    <p>Just like compiler converts high level language into machine level language an assembler converts assembly level language into machine levewl language</p>
                  </li>
                  <li>
                    <h3>
                      Interpreter
                    </h3>
                    <p>An Interpreter directly executes instructions written in a programming or scripting language without previously converting them to an object code or machine code. Examples of interpreted languages are Perl, Python and Matlab</p>
                  </li>
                  <li>
                    <h3>
                      System Calls
                    </h3>
                    <p>a system call is the programmatic way in which a computer program requests a service from the kernel of the operating system it is executed on. A system call is a way for programs to interact with the operating system. A computer program makes a system call when it makes a request to the operating system’s kernel. System call provides the services of the operating system to the user programs via <b>Application Program Interface(API)</b></p>
                  </li>
                  <li>
                    <h3>
                      Application Programming Interface(API)
                    </h3>
                    <p>API delivers a user response to a system and sends the system's response back to a user.</p>
                  </li>
                  <li>
                    <h3>
                      Kernel
                    </h3>
                    <p>A kernel is the central part of an operating system. It manages the operations of the computer and the hardware, most notably memory and CPU time.[1]

                      There are five types of kernels:
                      A micro kernel, which only contains basic functionality;
                      A monolithic kernel, which contains many device drivers.
                      Hybrid Kernel
                      Exokernel
                      Nanokernel</p>
                  </li>
                  <li>
                    <h3>
                      Shell
                    </h3>
                    <p>The shell is the outermost layer of the operating system. Shells incorporate a programming language to control processes and files, as well as to start and control other programs.
                      A shell is an environment in which we can run our commands, programs, and shell scripts.
                    </p>
                  </li>
                  <li>
                    <h3>
                      Booting
                    </h3>
                    <p>Booting is the process of starting a computer. It can be initiated by hardware such as a button press, or by a software command. After it is switched on, a computer's central processing unit (CPU) has no software in its main memory, so some process must load software into memory before it can be executed.</p>
                  </li>
                  <li>
                    <h3>
                      JVM
                    </h3>
                    <p>Java Virtual Machine (JVM) is a engine that provides runtime environment to drive the Java Code or applications. It converts Java bytecode into machines language. JVM is a part of Java Run Environment (JRE).
                      Due to JVM java is machine independent.
                    </p>
                  </li>
                  <li>
                    <h3>Multiprocessing</h3>
                    <p>
                      In a uni-processor system, only one process executes at a time.
Multiprocessing is the use of two or more CPUs (processors) within a single Computer system. The term also refers to the ability of a system to support more than one processor within a single computer system. Now since there are multiple processors available, multiple processes can be executed at a time. These multi processors share the computer bus, sometimes the clock, memory and peripheral devices also.
                    </p>
                  </li>
                  <li>
                    <h3>Multithreading</h3>
                    <p>
                      Its an extension of multitasking. 
                      Multi threading is an execution model that allows a single process to have multiple code segments (i.e., threads) running concurrently within the “context” of that process.
e.g. VLC media player, where one thread is used for opening the VLC media player, one thread for playing a particular song and another thread for adding new songs to the playlist.
Multi threading is the ability of a process to manage its use by more than one user at a time and to manage multiple requests by the same user without having to have multiple copies of the program.
                    </p>
                  </li>
                </ul>
                <h2>Steps which happen when we turn on our computer system</h2>
                <p><b>Step1:</b>The CPU Loads the UEFI or BIOS</p>
                <p><b>Step2:</b>The UEFI or BIOS Tests(POST - Power on self test) and Initializes Hardware</p>
                <p><b>Step3:</b>The UEFI or BIOS Hands Off to a Boot Device(Operating system's boot loader</p>
                <p><b>Step4:</b>The Bootloader Loads the Full OS</p>
              </article>
            </section>
            <section class="main-section" id="processconcept">
              <article>
                <header>
                  Process Concepts
                </header>
                <h3>Process VS Program</h3>
                <p>
                  Step1. When we write a program compiler converts it from High level lang to Machine level language and store in secondary memory.
                </p>
                <p>
                  Step2 . When we do some mouse click or commands to execute the program the OS(loader) will locate that program in secondary memory
                  or the instance to run and load it in the main memory. 
                </p>
                <p>Step3. In the main memory the OS will store it using some data structure to execute the program i.e. process</p>
                <table>
                  <tr>
                    <th>
                     Program
                    </th>
                    <th>
                      Process
                    </th>
                  </tr>
                  <tr>
                    <td>
                    	Program contains a set of instructions designed to complete a specific task.
                    </td>
                     <td>
                      Process is an instance of an executing program.
                     </td>
                  </tr>
                  <tr>
                    <td>
                      Program is a passive and static entity as it resides in the secondary memory.
                    </td>
                    <td>
                      Process is a active and dynamic entity as it is created during execution and loaded into the main memory.
                    </td>
                  </tr>
                  <tr>
                    <td>Program exists at a single place and continues to exist until it is deleted.</td>
                    <td>Process exists for a limited span of time as it gets terminated after the completion of task.</td>
                  </tr>
                  <tr>
                    <td>Program does not have any control block.</td>
                    <td>Process has its own control block called Process Control Block</td>
                  </tr>
                </table>
                <h2>States Of A Process</h2>
                <img alt="state" src="./state.PNG"/>
                <ul>
                  <li>New
                  <p>The program is in secondary mem and the process is about to be created but not yet created</p>
                </li>
                <li>Ready
                  <p>Process is created and is waiting to get CPU for execution</p>
                </li>
                <li>Running
                  <p>Process is being executed by the different cores of the CPU</p>
                </li>
                <li>Exit
                  <p>Process is completed and PCB is deleted</p>
                </li>
                <li>Blocked
                  <p>Process is doing I/O or trying to access some critical region so CPU idle so process is sent from running to blocked</p>
                </li>
                <li>Suspend Ready
                  <p>Due to incoming of a higher priority process and lack of space in ready queue lower priority process is sent to suspend ready state</p>
                </li>
                <li>Suspend Block
                  <p>Just as process is sent from ready to suspend ready if that process is in blocked it is sent to suspend block. Once it complete its i/O it can go to suspend ready</p>
                </li>
                </ul>
                <h3>Types Of Process</h3>
                <table>
                  <tr>
                    <th>
                      CPU Bound
                    </th>
                    <th>
                      I/O Bound
                    </th>
                  </tr>
                  <tr>
                    <td>
                      If process has lot of work in which CPU is required.
                    </td>
                     <td>
                      If process has lot of work in which I/O is required.
                     </td>
                  </tr>
                </table>
                <p>Best performance system is which have coimbination of CPU bound and I/O bound process.</p>
                <h2>Process Table</h2>
                <img src="./table.png">
                <p>The process table is an array of PCB’s, that means logically contains a PCB for all of the current processes in the system.</p>
                <h2>Process Control Block</h2>
                <img src="./pcb.PNG">
                <p> As the operating system supports multi-programming, it needs to keep track of all the processes. For this task, the process control block (PCB) is used to track the process’s execution status.</p>
                <ul>
                  <li>
                    <h3>
                      Pointer
                    </h3>
                    <p>
                      It is a stack pointer which is required to be saved when the process is switched from one state to another to retain the current position of the process.
                    </p>
                  </li>
                  <li>
                    <h3>
                      Process state
                    </h3>
                    <p>
                      Current state of process
                    </p>
                  </li>
                  <li>
                    <h3>
                      Process number 
                    </h3>
                    <p>
                      Every process is assigned with a unique id known as process ID or PID which stores the process identifier.
                    </p>
                  </li>
                  <li>
                    <h3>
                      Program Counter
                    </h3>
                    <p>
                      It contain a counter which stores the address of the next instruction to be executed.                      
                    </p>
                  </li>
                  <li>
                    <h3>
                     List of open files
                    </h3>
                    <p>
                     It contain list of all the files it has opened so that it can close it and not reopen it.   
                    </p>
                  </li>
                  <li>
                    <h3>
                      Register
                    </h3>
                    <p>
                      These are the CPU registers which includes: accumulator, base, registers and general purpose registers.
                      For eg : First P1 was executing and after its instruction I3 it stopped and P2 started executing then 
                      the values which were stored in CPU registers were also changed so P1 needs to store
                      the value of CPU registers as well. 
                    </p>
                  </li>
                  <li>
                    <h3>
                      Priority & Memory Limits
                    </h3>
                    <p>
                      Whenever any process is created it is assigned a priority by the CPU.
                      Processes with higher priority are executed first.OS process have higher priority than user process.
                      Memory limits tell about the memory management used by the OS.
                    </p>
                  </li>
                </ul>
                <h2>Process Structure</h2>
                <img src="./PR.PNG">
                <ul>
                  <li>
                    <h3>
                      Stack
                    </h3>
                    <p>
                      For recursion call.
                    </p>
                  </li>
                  <li>
                    <h3>
                      Heap
                    </h3>
                    <p>
                      This space is used when in future there is a calloc or malloc call.
                    </p>
                  </li>
                   <li>
                     <h3>
                       data
                     </h3>
                     <p>
                       Shared and global variables are stored - once created they remain in memory till the life of process.
                     </p>
                   </li>
                   <li>
                     <h3>
                       text
                     </h3>
                     <p>
                       It consist of executable code i.e. a.out
                     </p>
                   </li>
                </ul>
                <h2>Process VS Threads</h2>
                <img src="./thread.PNG"/>
                <table>
                  <tr>
                    <th>
                      Process
                    </th>
                    <th>
                      Threads
                    </th>
                  </tr>
                  <tr>
                    <td>
                      Process means any program is in execution.
                    </td>
                     <td>
                      Thread means segment of a process.
                     </td>
                  </tr>
                  <tr>
                    <td>
                      Process takes more time for termination, creation,context switching.
                      and also is less efficient and consume more resources so process are known as heavy weight process.
                    </td>
                    <td>
                      Threads takes less time for termination, creation,context switching.
                      and also is more efficient and consume less resources so threads are known as light weight process.
                    </td>
                  </tr>
                  <tr>
                    <td>
                      Process is isolated so 	If one process is blocked then it will not effect the execution of other process 
                    </td>
                    <td>
                      Threads share memory so Second thread in the same task couldnot run, while one server thread is blocked.
                    </td>
                  </tr>
                  <tr>
                    <td>
                      Process has its own Process Control Block, Stack and Address Space.
                    </td>
                    <td>
                      Thread has Parents’ PCB, its own Thread Control Block and Stack and common Address space.
                    </td>
                  </tr>
                </table>
                <h2>
                  Context Switching
                </h2>
                <p>Context Switching involves storing the context or state of a process so that it can be reloaded when required and execution can be resumed from the same point as earlier. This is a feature of a multitasking operating system and allows a single CPU to be shared by multiple processes.</p>
                For eg <em>initially Process 1 is running. Process 1 is switched out and Process 2 is switched in because of an interrupt or a system call. Context switching involves saving the state of Process 1 into PCB1 and loading the state of process 2 from PCB2. After some time again a context switch occurs and Process 2 is switched out and Process 1 is switched in again. This involves saving the state of Process 2 into PCB2 and loading the state of process 1 from PCB1.</em>
                <h3>Context switching triggers</h3>
                <ul>
                  <li>Multitasking</li>
                  <li>Interrupt Handling</li>
                  <li>User and Kernel Mode Switching.</li>
                </ul>
                <b>Why context switching between threads of same process is faster than between two process?</b>
                <p> As threads have the same virtual memory maps. Because of this TLB flushing is not required.</p>
                <h2>Inter Process Communication</h2>
                <p> Inter-process communication (IPC) is a mechanism that allows processes to communicate with each other and synchronize their actions. The communication between these processes can be seen as a method of co-operation between them</p>
                <p>Processes can communicate with each other through both:</p>
                <img src="./ipc.PNG"/>
                <ul>
                  <li><h3>Shared Memory</h3>
                  <p>Communication between processes using shared memory requires processes to share some variable, and it completely depends on how the programmer will implement it. 
                    <em>Suppose process1 and process2 are executing simultaneously, and they share some resources or use some information from another process. Process1 generates information about certain computations or resources being used and keeps it as a record in shared memory. When process2 needs to use the shared information, it will check in the record stored in shared memory and take note of the information generated by process1 and act accordingly.</em>
                    <p><b>Producer Consumer Problem</b></p>
                    <p>There are two processes: Producer and Consumer. The producer produces some items and the Consumer consumes that item. The two processes share a common space or memory location known as a buffer where the item produced by the Producer is stored and from which the Consumer consumes the item if needed</p>
                    <p>It is if two types</p>
                    <ul>
                      <li><b>Bounded buffer problem</b>
                      <p>Size of buffer is fixed so If the total produced item is equal to the size of the buffer, the producer will wait to get it consumed by the Consumer. Similarly, the consumer will first check for the availability of the item. If no item is available, the Consumer will wait for the Producer to produce it</p>
                      <em>Producer Process code</em>
                      <code>
                        item nextProduced;
     
    while(1){
         
        // check if there is no space
        // for production.
        // if so keep waiting.
        while((free_index+1) mod buff_max == full_index);
         
        shared_buff[free_index] = nextProduced;
        free_index = (free_index + 1) mod buff_max;
    }
                      </code>
                     <em>Consumer Process Code</em>
                     <code>
                         
    while(1){
         
      // check if there is an available
      // item  for consumption.
      // if not keep on waiting for
      // get them produced.
      while((free_index == full_index);
       
      nextConsumed = shared_buff[full_index];
      full_index = (full_index + 1) mod buff_max;
  }
                     </code>
                      </li>
                      <li><b>Unbounded buffer problem</b>
                        <p>Producer can keep on producing items and there is no limit on the size of the buffer</p>
                        </li>
                    </ul>
                  </p>
                </li>
                <li><h3>Message Passing</h3>
                  <p>
                    In this method, processes communicate with each other without using any kind of shared memory. If two processes p1 and p2 want to communicate with each other, they 
                  </p>
                  <ol>
                    <li>
                      Establish a communication link (if a link already exists, no need to establish it again.)
                    </li>
                    <li>
                      Start exchanging messages using basic primitives.
We need at least two primitives: 
– send(message, destination) or send(message) 
– receive(message, host) or receive(message).<br/>
A standard message can have two parts: header and body. 
The header part is used for storing message type, destination id, source id, message length, and control information.
                    </li>
                  </ol>
                  <p>It is of two types</p>
                  <ul>
                    <li>
                      <b>Direct Message Passing</b>
                      <p>When the processes use a specific process identifier for the communication, but it is hard to identify the sender ahead of time. </p>
                      <em>Print server</em>
                      <p>e.g. send(p1, message) means send the message to p1. 
                        Similarly, receive(p2, message) means to receive the message from p2. </p>
                        <b>Symmetric</b>
                        <p> both processes will name each other for sending and receiving the messages</p>
                        <b>Asymmetric</b>
                        <p>only the sender will name the receiver for sending the message and there is no need for the receiver for naming the sender for receiving the message.</p>
                        <em>The problem with this method of communication is that if the name of one process changes, this method will not work.</em>
                    </li>
                    <li>
                      <b>
                        Indirect Message Passing
                      </b>
                      <p>It is done via a shared mailbox (port), which consists of a queue of messages. The sender keeps the message in mailbox and the receiver picks them up.</p>
                    </li>
                  </ul>
                </li>
                </ul>
              <h3>What is a pipe?</h3>
              <p>
                Pipe is a communication medium between two or more related or interrelated processes. It can be either within one process or a communication between the child and the parent processes. Communication can also be multi-level such as communication between the parent, the child and the grand-child, etc. Communication is achieved by one process writing into the pipe and other reading from the pipe. To achieve the pipe system call, create two files, one to write into the file and another to read from the file.
                
                Pipe mechanism can be viewed with a real-time scenario such as filling water with the pipe into some container, say a bucket, and someone retrieving it, say with a mug. The filling process is nothing but writing into the pipe and the reading process is nothing but retrieving from the pipe. This implies that one output (water) is input for the other (bucket).</p>
                <img src="./Pipe.PNG"/>
                <h2>Zombie Process</h2>
                <p>When a process is created in UNIX using fork() system call, the address space of the Parent process is replicated. If the parent process calls wait() system call, then the execution of parent is suspended until the child is terminated. At the termination of the child, a ‘SIGCHLD’ signal is generated which is delivered to the parent by the kernel. Parent, on receipt of ‘SIGCHLD’ reaps the status of the child from the process table. Even though, the child is terminated, there is an entry in the process table corresponding to the child where the status is stored. When parent collects the status, this entry is deleted. Thus, all the traces of the child process are removed from the system. If the parent decides not to wait for the child’s termination and it executes its subsequent task, then at the termination of the child, the exit status is not read. Hence, there remains an entry in the process table even after the termination of the child. This state of the child process is known as the Zombie state.</p>
                <h3>Ways to prevent creation of zombie process</h3>
                <ul>
                  <li>Using wait system call</li>
                  <li>Using SIGNAL(SIG_CHLD,SIG_IGN)</li>
                  <li>Using signal handler</li>
                </ul>
               <b> <h3>What are the maximum number of zombie process system can handle?</h3></b>
                <p>
                  Basically, Zombie Process is neither completely dead nor completely alive but it has having some state in between.

                  Since, there is an entry for all the process in process table, even for Zombie Processes. It is obvious that size of process table is Finite. So, if zombie process is created in large amount, then Process Table will get filled up and program will stop without completing their task.
                  to find out Maximum Number of Zombie Process created so that Program will not stop its execution we will create a zombie process within a loop and count it until the program does not stop the execution.
                </p>
              </article>
            </section>
            <section class="main-section" id="processscheduling">
              <article>
                <header>
                  Process Scheduling
                </header>
                  <h3>What is process Scheduling?</h3>
                  <p>The process scheduling is the activity of the process manager that handles the removal of the running process from the CPU and the selection of another process on the basis of a particular strategy.

Process scheduling is an essential part of a Multiprogramming operating systems. Such operating systems allow more than one process to be loaded into the executable memory at a time and the loaded process shares the CPU using time multiplexing.</p>
                  <h3>Why process scheduling?</h3>
                  <p>1. It allows OS to allocate time interval of CPU execution for each process.<br/>
                    2. It keeps the CPU busy all time . It allows us to get the minimum response time for programs.</p>
                  <h3>Schedulers and its types?</h3>
                  <p>
                    Scheduler are special system software which handle process scheduling in various ways.
                    Their main task is to select the jobs to be submitted to the system and to decide which process to run.They are of three types:
                    <ul>
                      <li>
                        <b>Long Term Scheduler</b>
                        <p>Decision of how many processes to create.Long term scheduler is also known as a job scheduler. This scheduler regulates the program and select process from the queue and loads them into memory for execution. It also regulates the degree of multi-programing.

                          However, the main goal of this type of scheduler is to offer a balanced mix of jobs, like Processor, I/O jobs., that allows managing multiprogramming.</p>
                      </li>
                      <li>
                        <b>
                          Medium term scheduler
                        </b>
                        <p>
                          Decision of which process to suspend and which to send to secondary memory.
                          Medium-term scheduling is an important part of swapping. It enables you to handle the swapped out-processes. In this scheduler, a running process can become suspended, which makes an I/O request.

A running process can become suspended if it makes an I/O request. A suspended processes can't make any progress towards completion. In order to remove the process from memory and make space for other processes, the suspended process should be moved to secondary storage.
                        </p>
                      </li>
                      <li>
                        <b>
                          Short term scheduler
                        </b>
                        <p>
                          Decision of which process in ready queue is to be sent to running state.
                          Short term scheduling is also known as CPU scheduler. The main goal of this scheduler is to boost the system performance according to set criteria. This helps you to select from a group of processes that are ready to execute and allocates CPU to one of them. The dispatcher gives control of the CPU to the process selected by the short term scheduler.
                        </p>
                        <em>When is a CPU scheduler invoked?</em>
                        <p>When a process switches from :</p>
                        <ol>
                          <li>running to waiting state(cpu scheduling is necessary)</li>
                          <li>running to ready state(cpu scheduling is optional)</li>
                          <li>waiting to ready state(cpu scheduling is optional)</li>
                          <li>Terminates(cpu scheduling is necessary)</li>
                        </ol>
                      </li>
                    </ul>
                  </p>
                  <h3>Scheduling Queue</h3>
                  <p>The OS maintains all PCBs in Process Scheduling Queues. The OS maintains a separate queue for each of the process states and PCBs of all processes in the same execution state are placed in the same queue. When the state of a process is changed, its PCB is unlinked from its current queue and moved to its new state queue.

                    The Operating System maintains the following important process scheduling queues −
                    <img src="./queue.PNG"/>
                    <ul>
                      <li>
                        Job queue − This queue keeps all the processes in the system.
                      </li>
                      <li>
                        Ready queue − This queue keeps a set of all processes residing in main memory, ready and waiting to execute. A new process is always put in this queue.
                      </li>
                      <li>
                        Device queues − The processes which are blocked due to unavailability of an I/O device constitute this queue.
                      </li>
                    </ul>
                </p>
                <b>What is a CPU burst cycle?</b>
                <p>The execution fo a process consist of alternate Cpu bursts and I/O bursts,starting and ending with CPU burst.</p>
                <h3>Preemptive VS Non-Preemptive Scheduling</h3>
                <table>
                    <tr>
                      <th>
                        Preemptive 
                      </th>
                      <th>
                        Non-Preemptive
                      </th>
                    </tr>
                    <tr>
                      <td>
                        A process can be forced to leave the CPU and enter ready queue.
                      </td>
                      <td>
                        Cooperative scheduling where a process keeps the CPU until it terminates or switches to waiting state.
                      </td>
                    </tr>
                    <tr>
                      <td>
                        Windows 3.1
                      </td>
                      <td>
                        Unix,Linux,Windows 95.
                      </td>
                    </tr>
                    <h3>Dispatcher</h3>
                    <p>It is the module of operating system that gives control of the CPU to the process selected 
                      by the CPU scheduler (short term scheduler)
                    </p>
                    <p>Steps :
                      <ol>
                        <li>Switching context</li>
                        <li>Switching to user mode</li>
                        <li>jumping to proper location in user program.</li>
                      </ol>
                    </p>
                    <b>Dispatch Latency</b>
                    <p>It is the time taken to stop a process and start another.Its a complete overhead</p>
                </table>
                <b>Discuss Scheduling Criteria:</b>
                <p><ol>
                  <li>High CPU utilization</li>
                  <li>High <em>throuput</em>number of processes completed per unit time</li>
                  <li>Low <em>turnaroundtime</em>Time from submission to completion (time spent in different 
                    queues + time spent in CPU + time spent in different i/o 
                    devices) </li>
                    <li>Low<em>Response time</em> time from submission to first response i.e. first time a process is assigned CPU.</li>
                    <li>Low <em>Waiting Time</em>time spend in the ready queue (only)</li>
                </ol></p>
                <h3>Process Scheduling Algorithms</h3>
                <table>
                  <tr>
                   <th>Name</th>
                   <th>FCFS</th>
                   <th>SJF</th>
                   <th>SRTF</th>
                   <th>Priority</th>
                   <th>Round Robin</th>
                   <th>Multi Level Queue Scheduling</th>
                   <th>Multi Level Feedback queue scheduling</th>
                  </tr>
                  <tr>
                    <th>Criteria</th>
                    <td>Arrival Time</td>
                    <td>Burst Time</td>
                    <td>Burst Time</td>
                    <td>Priority</td>
                    <td>Time Quantum fixed</td>
                    <td>Ready queue divided in separate queues one with higher priorities exec first</td>
                    <td>Ready queue divided in separate queues one with higher priorities exec first but inter queue movement</td>
                   </tr>
                   <tr>
                    <th>Mode</th>
                    <td>Non Preemptive</td>
                    <td>Non Preemptive</td>
                    <td> Preemptive</td>
                    <td>Preem/Non Preemptive</td>
                    <td>Preemptive</td>
                    <td>Non Preemptive</td>
                    <td>Preemptive</td>
                   </tr>
                   <tr>
                    <th>Break Ties</th>
                    <td>less Pid</td>
                    <td>FCFS</td>
                    <td>FCFS</td>
                    <td>FCFS</td>
                    <td>NO Criteria if tq is very high (FCFS) if less tq processor sharing</td>
                    <td>NO </td>
                    <td>queue movement</td>
                   </tr>
                   <tr>
                    <th>Advantage</th>
                    <td>Simple</td>
                    <td>Most efficient</td>
                    <td>Optimal</td>
                    <td>Low WT for high priority process</td>
                    <td>No indefinite blocking</td>
                    <td>High priority not wait</td>
                    <td>Less starvation</td>
                   </tr>
                   <tr>
                    <th>Disadvantages</th>
                    <td>High avg WT , <b>Convoy effect</b>
                    If a process arrives early it will aqquire the CPU and if it has large burst time the other processes will suffer from starvation</td>
                    <td>Practically not possible</td>
                    <td>Practically not possible</td>
                    <td>Starvation of low priority processes</td>
                    <td>High context switching</td>
                    <td>Starvation,Complex</td>
                    <td>Complex</td>
                   </tr>

                </table>
                <em>Round robin is used most in real world scenario</em>
                <br/>
                <b>Ageing</b>
                <p> gradually increase the priority of a process waiting for a long time 
                  <b>priority inversion</b>: a low-priority process gets the priority of a high-priority process waiting 
                  for it </p>
              </article>

            </section>
            <section class="main-section" id="threadconcept">
              <article>
                <header>Thread Concept</header>
                <h3>What are Threads?</h3>
                <p>Thread is an execution unit that consists of its own program counter, a stack, and a set of registers where the program counter mainly keeps track of which instruction to execute next, a set of registers mainly hold its current working variables, and a stack mainly contains the history of execution</p>
                <h3>Advantages Of Multithreading</h3>
                <ol><li>
            
                 <b> Responsiveness</b> –
Multithreading in an interactive application may allow a program to continue running even if a part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user.
In a non multi threaded environment, a server listens to the port for some request and when the request comes, it processes the request and then resume listening to another request. The time taken while processing of request makes other users wait unnecessarily. Instead a better approach would be to pass the request to a worker thread and continue listening to port.

For example, a multi threaded web browser allow user interaction in one thread while an video is being loaded in another thread. So instead of waiting for the whole web-page to load the user can continue viewing some portion of the web-page.
                </li>
                <li><b>Economical</b>:More efficient require less resources and faster and smoother context switching</li>
                <li><b>Enhanced Throughput </b>of the system. Let us take an example for this: suppose a process is divided into multiple threads, and the function of each thread is considered as one job, then the number of jobs completed per unit of time increases which then leads to an increase in the throughput of the system.</li>
                <li>
                 <b> Scalability </b>–
The benefits of multi-programming greatly increase in case of multiprocessor architecture, where threads may be running parallel on multiple processors. If there is only one thread then it is not possible to divide the processes into smaller tasks that different processors can perform.
Single threaded process can run only on one processor regardless of how many processors are available.
Multi-threading on a multiple CPU machine increases parallelism.
                </li>
                </ol>
                <em><h3>Example of some multithreaded applications.</h3></em>
                <ol>
                  <li>
                    <b>Web browser</b>
                    <p>A web browser can download any number of files and web pages (multiple tabs) at the same time and still lets you continue browsing. If a particular web page cannot be downloaded, that is not going to stop the web browser from downloading other web pages.
                    </p>
                  </li>
                  <li>
                    <b>
                      Web Servers
                    </b>
                    <p>
                      A threaded web server handles each request with a new thread. There is a thread pool and every time a new request comes in, it is assigned to a thread from the thread pool.
                    </p>
                  </li>
                  <li>
                    <b>
                      Computer Games 
                    </b>
                    <p>
                      You have various objects like cars, humans, birds which are implemented as separate threads. Also playing the background music at the same time as playing the game is an example of multithreading.
                    </p>
                  </li>
                  <li>
                    <b>
                      Text Editors
                    </b>
                    <p>
                      When you are typing in an editor, spell-checking, formatting of text and saving the text are done concurrently by multiple threads. The same applies for Word processors also.
                    </p>
                  </li>
                </ol>
                <h3>Types Of Thread</h3>
                <table>
                  <tr>
                    <th>
                      User Level Thread
                    </th>
                    <th>
                      Kernel Level Thread
                  </th>
                  </tr>
                  <tr>
                    <td>
                      It is implemented by user and not recognized by os.
                    </td>
                    <td>
                      It is implemented and recognized by os.
                    </td>
                  </tr>
                  <tr>
                    <td>
                      Its context switching does not require hardware support.
                    </td>
                    <td>
                      Its context switching require hardware support.
                    </td>
                  </tr>
                  <tr>
                    <td>
                      If one is blocked other will also be blocked as they are designed as dependent threads.For eg : Java, Posix thread.
                    </td>
                    <td>
                      If one is blocked other will not be blocked as they are designed as independent threads.For eg : Window Solaris thread.
                    </td>
                    <tr>
                      <td>
                        Implementation done by thread library so generic in nature and can run on any os.
                      </td>
                      <td>
                        Implementation done by os so complex in nature and can run on specific os.
                      </td>
                    </tr>
                  </tr>
                </table>
                <h3>Types Of MultithreadingModels</h3>
                <em>The user threads must be mapped to kernel threads, by one of the following strategies:</em>
                <table>
                  <tr>
                    <th>
                      Many To One
                    </th>
                    <th>
                      One To One
                  </th>
                  <th>
                    Many To Many
                  </th>
                  </tr>
                  <tr>
                    <td>
                      many user-level threads are all mapped onto a single kernel thread.
                    </td>
                    <td>
                      The one to one model creates a separate kernel thread to handle each and every user thread.
                    </td>
                    <td>The many to many model multiplexes any number of user threads onto an equal or smaller number of kernel threads, combining the best features of the one-to-one and many-to-one models.</td>
                  </tr>
                  <tr>
                    <td>
                      In this case, if user-level thread libraries are implemented in the operating system in some way that the system does not support them, then the Kernel threads use this many-to-one relationship model.

                    </td>
                    <td>
                      Most implementations of this model place a limit on how many threads can be created.Linux and windows use this
                    </td>
                    <td>
                      There is a thread pool only some threads are mapped to kernel thread once pool is filled we wait for the task to complete.
                    </td>
                  </tr>
                  <tr>
                    <td>
                      <img src="./mto.PNG" style="width: 20vw;height: 20vw;"/>
                    </td>
                    <td>
                      <img src="./oto.PNG"style="width: 20vw;height: 20vw;"/>
                    </td>
                    <td>
                      <img src="./mtm.PNG"style="width: 20vw;height: 20vw;"/>
                    </td>
                  </tr>
                </table>
                <b><p>Optimal Number of threads required for a process??</p></b>
                <p>If your threads don't do I/O, synchronization, etc., and there's nothing else running, 1 thread per core will get you the best performance. However that very likely not the case. Adding more threads usually helps, but after some point, they cause some performance degradation.
                  So the best way is to test with different number of threads until you find the right number for your application as it depends on the system configuration , application and other factors.
                  It is not that using large number of threads will always help as it can even degrade performance by doing lot of context switching
                </p>
                <b><p>Effect of multiple cores on multi-threading??</p></b>
                <p> It is fairly widely understood that multithreading bugs are more likely to manifest on multi-processor platforms
                  <em>Try doing again</em>
                </p>
                <b><p>Why static variables are considered evil in real life operating system?</p></b>
                <p>Since static variables represent global state which are hard to test and reason so it will not be a good design as the code would not be that testable.</p>
              </article>
            </section>
           <section class="main-section" id="synchronisation">
             <article>
               <header>
                 Process Synchronization
               </header>
               <h3>What is process synchronisation??</h3>
               <p>Based on synchronisation there are two types of process:</p>
               <b>Independent process:</b>Execution of one process does not affect other.<br/>
               <b>Cooperative process:</b>Execution of one process affect other.So for smooth functioning of these process they should be synchronised.
               <p>It is the task phenomenon of coordinating the execution of processes in such a way that no two processes can have access to the same shared data and resources at the same time.</p>
               <p>It is used to maintain appropriate order of execution of cooperative processes. </p>
               <h3>Race Condition</h3>
               <p>At the time when more than one process is either executing the same code or accessing the same memory or any shared variable; In that condition, there is a possibility that the output or the value of the shared variable is wrong so for that purpose all the processes are doing the race to say that my output is correct. This condition is commonly known as a race condition. As several processes access and process the manipulations on the same data in a concurrent manner and due to which the outcome depends on the particular order in which the access of data takes place.</p>
               <h3>Logical Address VS Physical Address</h3>
               <img src="./logandphy.PNG"/>
               <table>
                 <tr>
                   <th>
                     Logical Address
                   </th>
                   <th>
                     Physical Address
                   </th>
                 </tr>
                 <tr>
                   <td>
                    Logical Address is generated by CPU while a program is running. The logical address is virtual address as it does not exist physically, therefore, it is also known as Virtual Address
                   </td>
                   <td>
                    Physical Address identifies a physical location of required data in a memory
                   </td>
                 </tr>
                 <tr>
                   <td>
                    Logical Address Space is set of all logical addresses generated by CPU in reference to a program.
                   </td>
                   <td>
                    Physical Address is set of all physical addresses mapped to the corresponding logical addresses.
                   </td>
                 </tr>
                 <tr>
                   <td>
                    User can view the logical address of a program.
                   </td>
                   <td>
                    User can never view physical address of program.
                   </td>
                 </tr>
                 <tr>
                   <td>
                     Generated by CPU
                   </td>
                   <td>
                     Computed by MMU.
                   </td>
                 </tr>
               </table>
               <h3>Critical Section In Synchronization</h3>
               <p>When more than one processes access a same code segment that segment is known as critical section. Critical section contains shared variables or resources which are needed to be synchronized to maintain consistency of data variable.</p>
               <code>acquireLock();
                Process Critical Section
                releaseLock();</code>
                <p>A thread must acquire a lock prior to executing a critical section. The lock can be acquired by only one thread. There are various ways to implement locks</p>
               <h3>Mutual Exclusion In Synchronization</h3>
               <em> The primary task of process synchronization is to get rid of race conditions while executing the critical section.
                This is primarily achieved through mutual exclusion.</em>
                <p>Mutual exclusion is a property of process synchronization which states that “no two processes can exist in the critical section at any given point of time”.
                  Any process synchronization technique being used must satisfy the property of mutual exclusion, without which it would not be possible to get rid of a race condition.
                </p>
                <h3>Progress</h3>
                <p>Out of all the processes only interested ones should be considered to enter the critical section and the decision should be taken in finite time.</p>
                <h3>Bounded Wait Time</h3>
                <p>There should be a limit on the number of times a process can enter a critical section when other processes are also waiting to enter the critical section.</p>
                <h3>Software Solution To Critical Section Problem</h3>
                <b>Peterson Solution</b>
                <p>It is a program used to solve critical section problem . It only works when there are two processes who are trying to access the same shared variable concurrently leading to race condition</p>
                <p>It is a combination of turn and flag variable solution and satisfy all the above conditions</p>
                <code>
                  // code for producer (j)
  
// producer j is ready
// to produce an item
//process j says i am interested
flag[j] = true;
  
// but consumer (i) can consume an item
//it gives i to execute next
turn = i;
  
// if consumer is ready to consume an item
// and if its consumer's turn
//if other process is interested and executing current will keep on waiting #mutual exclusion
while (flag[i] == true && turn == i)
//if flag is false means process is not interested it cant enter so #progress is achieved

    { // then producer will wait }
  
    // otherwise producer will produce
    // an item and put it into buffer (critical Section)
  
    // Now, producer is out of critical section
    flag[j] = false;
    //Now by setting flag as false giving chance to other process #bounded wait is achieved
    // end of code for producer
  
    //--------------------------------------------------------
    // code for consumer i
  
    // consumer i is ready
    // to consume an item
    flag[i] = true;
  
    // but producer (j) can produce an item
    turn = j;
  
    // if producer is ready to produce an item
    // and if its producer's turn
    while (flag[j] == true && turn == j)
  
        { // then consumer will wait }
  
        // otherwise consumer will consume
        // an item from buffer (critical Section)
  
        // Now, consumer is out of critical section
        flag[i] = false;
// end of code for consumer
                </code>
                <h3>Why preemptive kernels are better than non-preemprive kernels??</h3>
                <p>Preemptive kernel is more suitable for real time programming as compared to non-preemptive kernels as :
                  <ol>
                    <li>Responsive time is deterministic and is more responsive as compared to non-preemptive kernel.</li>
                    <li>They are more secure</li>
                    <li>In non-preemptive kernels Higher priority task might have to wait for long time.</li>
                  </ol>
                </p>
                <h3>Semaphore</h3>
                <p>It is a synchronization tool used in process synchronization.</p>
                <p>It is an integer variable that is accessed only through two atomic operations wait and signal </p>
                <b>Wait</b>
                <code>
                  //s is semaphore val
                  //in wait we wait for signal from another process
                  //here we decrease semaphore value
                  Wait(s)
                  {
                    while(s<=0)
                    //no operation and decrease value of s--
                    s--;
                  }
                </code>
                <b>Sinal</b>
                <code>
                  //s is semaphore val
                  //in signal 
                  //here we increase semaphore value
                  Wait(s)
                  {
                    s++;
                  }
                </code>
                <em>Modification to the integer value of the semaphore in wait and signal must be executed indivisibly.Only one process can modify semaphore val at a time.</em>
                <h3>Types of semaphore</h3>
                <table>
                  <tr>
                    <th>
                      Counting Semaphore
                    </th>
                    <th>
                      Binary Semaphore/Mutex Lock
                    </th>
                  </tr>
                  <tr>
                    <td>
                      Range over unrestricted domain.
                    </td>
                    <td>
                      Range over (0,1).
                      Also called as mutex locks as they provide mutual exclusion.
                    </td>
                  </tr>
                  <tr>
                    <td>
                      They are used to control access to a given resource consisting of finite number of instances.
                      For eg : if there is a printer (resource) having 5 instances than semaphore value of printer will be 5 P(S) = 5
                    </td>
                    <td>
                      It is used to apply lock. For eg : If there are two users who want to access printer then while one is accessing the resource the other will not be allowed to access it.
                    </td>
                  </tr>
                </table>
                <h3>Working of semaphore</h3>
                <p>Let us consider above ex where we have 5 instances of printer resource</p>
                <ol>
                  <li>Initialize value of semaphore s=5</li>
                  <li>Now if a process p wants to access the resource so first it will use the wait operation on semaphore s to check whether it is allowed to access resource or not</li>
                  <li>Now if it is allowed in the wait operation it will decrease value of s to 4 </li>
                  <li>After its operation is done it will perform the signal operation on semaphore where it will increase value of s back to 5 , as now the instance of resource he was using is free.</li>
                </ol>
                <em>Semaphore can also be used to solve many synchrnization problems</em>
                <p>For eg : If P1 want to access S1 stmt and P2 wants to access S2 such that S2 should be executed only after S1</p>
                <ol>
                  <li>Initialize a var synch as 0</li>
                  <li>After P1 has accessed S1 it will execute signal where it will increase synch to 1</li>
                  <li>Since P1 will perform wait so until value of synch is >0 P1 cant execute S1</li>
                  <li>Here synchronization is achieved</li>
                </ol>
                <h3><b>Disadvantages of semaphore</b></h3>
                <ol>
                  <li>
                    <em>Busy Waiting</em>
                    <p>When a process is in critical section only other process that tries to enter critical section must loop continuosly in its entry code.</p>
                  </li>
                  <li>
                    <em>Spin lock</em>
                    <p>It is a type of busy waiting : This lock causes the process/thread to simply wait in a loop if some other process is accessing the resource.</p>
                  </li>
                </ol>
                <table>
                  <em>It lets the process wait for indefinite time so not productive</em>
                  <tr>
                    <th>
                      Mutex
                    </th>
                    <th>
                      Spin Lock
                    </th>
                  </tr>
                  <tr>
                    <td>
                      We do not use while loop instead we let other process sleep so CPU wont have to spend time for doing nothing, but here we need to perform context switching.
                    </td>
                    <td>
                       Here we use while loop so process will have to be active and keep on checking locks.
                    </td>
                  </tr>
                </table>
                <h3>Inplement binary semaphore in real world coding??</h3>
                <em>
                 1. P operation is also called wait, sleep, or down operation, and V operation is also called signal, wake-up, or up operation.</em>
                 <em>Both operations are atomic and semaphore(s) is always initialized to one.</em>
                <code>
                  struct semaphore {
                    enum value(0, 1);
                 
                    // q contains all Process Control Blocks (PCBs)
                    // corresponding to processes got blocked
                    // while performing down operation.
                    Queue process> q;
                 
                } P(semaphore s)
                {
                    if (s.value == 1) {
                        s.value = 0;
                    }
                    else {
                        // add the process to the waiting queue
                        q.push(P)
                        sleep();
                    }
                }
                V(Semaphore s)
                {
                    if (s.q is empty) {
                        s.value = 1;
                    }
                    else {
                 
                        // select a process from waiting queue
                        Process p=q.pop();
                        wakeup(p);
                    }
                }
                </code>
                <h3>Deadlock VS Starvation</h3>
                <img src="./deadlock.PNG"/>
                <table>
                  <tr>
                    <th>
                      Deadlock
                    </th>
                    <th>
                      Starvation
                    </th>
                  </tr>
                  <tr>
                    <td>
                      All processes keep waiting for each other to complete and none get executed.
                     </td>
                     <td>
                      High priority processes keep executing and low priority processes are blocked
                     </td>
                  </tr>
                  <tr>
                    <td>
                      Resources are blocked by the processes
                    </td>
                    <td>
                      Resources are continuously utilized by high priority processes
                    </td>
                  </tr>
                  <tr>
                    <td>
                      Necessary conditions Mutual Exclusion, Hold and Wait, No preemption, Circular Wait
                    </td>
                    <td>
                      Priorities are assigned to the processes
                    </td>
                  </tr>
                  <tr>
                    <td>
                      Also known as Circular wait
                    </td>
                    <td>
                      Also know as lived lock
                    </td>
                  </tr>
                  <tr>
                    <td>
                      It can be prevented by avoiding the necessary conditions for deadlock
                    </td>
                    <td>
                      It can be prevented by Aging
                    </td>
                  </tr>
                </table>
                <h2>Classical Problems On Synchronization</h2>
               <h3><b>Bounded Buffer</b></h3>
               <p>The bounded-buffer problems (aka the producer-consumer problem) is a classic example of concurrent access to a shared resource. A bounded buffer lets multiple producers and multiple consumers share a single buffer. Producers write data to the buffer and consumers read data from the buffer.</p>
                <p>The size of buffer is fixed lets say if it is n then buffer can store max n items.</p>
               <p>Here we have three variables</p>
               <ol>
                 <li>Mutex : It is the mutual exclusion variable which is 1 if critical section is free and 0 if critical section is occupied</li>
                 <li>Full : It stores the number of entries of buffer already filled</li>
                 <li>Empty : It stores the number of entries of buffer which are empty.</li>
               </ol>
               <h3>Structure Of producer code</h3>
               <code>
                 //here it will check if there is space in the buffer then will decrease value of empty space by 1.
                 //if empoty space is <=0 it will get blocked
                 it will produce an item in pnext
                 wait(empty)
                 //if mutex==1 i.e. critical section then it will decrease it to 0 i.e. critical section occupied.
                 //if mutex =0 then get blocked
                 wait (mutex)
                 ********************Critical Section *******************
                 buffer <= pnext
                 ********************************************************
                 //it is leaving cs so will make mutex back to 1
                 signal(mutex)
                 //it has occupied one space so will increase value of occupied space.
                 signal(full)
               </code>
               <h3>Structure Of Consumer code</h3>
               <code>
                 //here it will check if there is item in the buffer then will decrease value of occupied space by 1.
                 //if occupied space is <=0 it will get blocked
                 wait(full)
                 //if mutex==1 i.e. critical section then it will decrease it to 0 i.e. critical section occupied.
                 //if mutex =0 then get blocked
                 wait (mutex)
                 ********************Critical Section *******************
                 consume item in nextC
                 nextC <= buffer
                 ********************************************************
                 //it is leaving cs so will make mutex back to 1
                 signal(mutex)
                 //it has occupied one space so will increase value of occupied space.
                 signal(empty)
               </code>
               <h3>Reader-Writer Problem</h3>
               <p>
                 There is a single file one person is writing in that file other is reading.
               </p>
               Rules
               <ol>
                <li>
                  Only one writer is allowed to write at a time.
                </li>
                <li>
                  When a writer is writing no reader is allowed to read.
                </li>
                <li>Multiple readers can read simultaneously.</li>
                <li>At the time of reading writing is not allowed.</li>
               </ol>
               <b>Solution using binary semaphore</b>
               <em>Soliton 1 : This solution ensures that at a time only one reader or one writer is allowed to enter critical section.</em>
               Code solution at writer
               //initially value of mutex is 1 i.e. no lock
               <code>
                 //it will make mutex=0 i.e put lock
                 wait(mutex)
                 Write here
                 //after work done again free the lock by making mutex =1 
                 signal(mutex)
               </code>
               Code solution at reader
               //initially value of mutex is 1 i.e. no lock
               <code>
                 //it will make mutex=0 i.e put lock
                 wait(mutex)
                 Read here
                 //after work done again free the lock by making mutex =1 
                 signal(mutex)
               </code>
               <em>Solution 2 : Since we want multiple readers to be allowed to read together</em>
               <p>So only first reader will execute wait i.e. check for mutex=1 rest readers can directly enter the critical section</p>
                To achieve this:
                Writers code will remain same
                For readers only first reader will acquire the lock and last reader will release the lock
                <em>it maybe diff reader will try to access same var creating sync problem so another sync var will be used for them</em>
                <code>
                 wait(rdmutex)
                  readers++
                  if(reader==1)
                    wait(mutex)
                  signal(rdmutex)
                  Read Here
                  wait(rdmutex)
                  readers--
                  if(readers==0)
                  signal(mutex)
                  signal(rdmutex)
                </code>
               <h3>Dining Philosopher Problem</h3>
               <img src="./dining.PNG"/>
               <p>Philosophers are sitting around a table and they are dining, they have one central ball of food and chopsticks between plates whenever they feel hungry they will acquire the adjaent chopsticks if they are available and take food from central ball to their plate and after eating they will release the chopsticks so we need to synchronize chopsticks.</p>
               <em>ith philosopher can access ith and i+1%5th chopstick</em>
               Dining philosopher Algorithm
               Chopstick is an array of location [0,4] where all the locations can hold a semaphore and will be initialized to value 1 i.e. no lock
               <code>
                repeat
                   wait(chopstick[i])
                   wait(chopstick[(i+1)%5])
                   **********
                   eat
                   *********
                   signal(chopstick[i])
                   signal(chopstick[(i+1)%5])
                   *******
                   think
                until false
               </code>
               <b>Above code can result in deadlock so solution</b>
               <ol>
                 <li>
                  Allow max 4 philosophers so atleast one philosopher will have 2 chopsticks
                 </li>
                 <li>
                   Philosophers can start eating only when they have 2 chopsticks.
                 </li>
                 <li>
                    The philosophers with even numbers will take right chopstick and with odd number will take left chopstick.
                 </li>
               </ol>
             </article>
           </section>
           <section class="main-section" id="deadlock">
             <article>
               <header>Deadlock</header>
               <h3>What is deadlock?</h3>
               <p>In general, resources allocated to a process are not preemptable; this means that once a resource has been allocated to a process, there is no simple mechanism by which the system can take the resource back from the process unless the process voluntarily gives it up or the system administrator kills the process. This can lead to a situation called deadlock. A set of processes or threads is deadlocked when each process or thread is waiting for a resource to be freed which is controlled by another process. Here is an example of a situation where deadlock can occur.</p>
               <code>
                Mutex M1, M2;

                /* Thread 1 */
                while (1) {
                   NonCriticalSection()
                   Mutex_lock(&M1);
                   Mutex_lock(&M2);
                   CriticalSection();
                   Mutex_unlock(&M2);
                   Mutex_unlock(&M1);
                }
                
                /* Thread 2 */
                while (1) {
                   NonCriticalSection()
                   Mutex_lock(&M2);
                   Mutex_lock(&M1);
                   CriticalSection();
                   Mutex_unlock(&M1);
                   Mutex_unlock(&M2);
                }
               </code>
               Suppose thread 1 is running and locks M1, but before it can lock M2, it is interrupted. Thread 2 starts running; it locks M2, when it tries to obtain and lock M1, it is blocked because M1 is already locked (by thread 1). Eventually thread 1 starts running again, and it tries to obtain and lock M2, but it is blocked because M2 is already locked by thread 2. Both threads are blocked; each is waiting for an event which will never occur.
               <em>Traffic gridlock is an everyday example of a deadlock situation.</em>
               <h3>Effect of Deadlock on other processes which are not deadlocked?</h3>
               <p>If OS has a deadlock prevention or detection system in place then it will have a negative impact on the performance because whenever a process or thread requests a resource the system will have to check whether grabtinbg this request could cause a potential deadlock situation.</p>
               <h3>Conditions for deadlock</h3>
               <p>In order for deadlock to occur, four conditions must be true.</p>
               <ol>
                 <li>
                   <b>Mutual exclusion</b>
                   <p> Each resource is either currently allocated to exactly one process or it is available. (Two processes cannot simultaneously control the same resource or be in their critical section).</p>
                 </li>
                 <li>
                   <b>Hold and Wait</b>
                   <p> processes currently holding resources can request new resources</p>
                 </li>
                 <li>
                   <b>No preemption</b>
                   <p>Once a process holds a resource, it cannot be taken away by another process or the kernel.</p>
                 </li>
                 <li>
                   <b>Circular wait</b>
                   <p>Each process is waiting to obtain a resource which is held by another process.</p>
                 </li>
               </ol>
               <h3>Ways to handle deadlock</h3>
               <ol>
                 <li>Prevention and deadlock : Make sure atleast one of the above four condition should not meet</li>
                 <li>Detection and recovery
                   <ul><li>
                     <h3>Bankers Algorithm</h3>
                     <p>Its also known as <b>deadlock avoidance</b> algo as here we will have to tell the os about how many process are going to arrive , which process , which resource,how many resource and for how much time.</p>
                      <p>It is also used for deadlock detection that to detect whether deadlock can ocur in future or not</p>
                      <p>Here given : no. of processes, no. of resources, no. of instances allocated, max need of every process, total instances of each resource avlbl</p>
                      <p>If deadlock then unsafe else safe then we will have safe sequence i.e. the sequence in which resources are allocated.</p>
                      <p>For that we will check remaining need and availablity if for all the processes remaining need > availability</p>
                      <b>It is not possible to implement it in real life</b>
                   </li>
                  <li>
                    <h3>
                      Ostrich Algorithm
                    </h3>
                    <p>Just as when cyclone occurs ostrich puyt iots head in sand and pretends as if no prblm has occured similarly we can just ignore when deadlock occurs</p>
                    <p>It is applicable only when deadlock occurs very rarely in our system and its very difficult to detect deadlock and very costly to avoid it. </p>
                    <em>Windows and Unix use this.</em>
                  </li>
                  <li>
                    <h3>
                      Resource Preemption
                    </h3>
                  </li>
                  </ul>
                 </li>
                 <li>
                   Ignorance
                 </li>
               </ol>
             </article>
           </section>
           <section id="memorymaanagementstrategy" class="main-section">
             <article>
                <header>
                  Main Memory Management
                </header>
                <p>Some Imp points</p>
                <ol>
                  <li>
                    CPU can directly access Registers and Main memory.
                  </li>
                  <li>
                    Protection of memory space is handled by the hardware.
                  </li>
                  <li>
                    OS loads Base and Limit Registers.
                  </li>
                  <li>
                    Mapping of logical to physical address is done by MMU.
                  </li>
                </ol>
                <h3>Swaping</h3>
                <p>
                  Swapping is a memory management scheme in which any process can be temporarily swapped from main memory to secondary memory so that the main memory can be made available for other processes. It is used to improve main memory utilization.
                </p>
                <ul>
                  <li>Ex : Priority based scheduling</li>
                  <li>Done by dispatcher</li>
                  <li>Context switching time in swapping is very high</li>
                  <li>OS cant swap process having pending I/P O/P.</li>
                  <li>Mobile phones do not support swapping they terminate the process if sufficient memory is not available.</li>
                </ul>
             <p>Ideal memory characteristics</p>
             <ol>
               <li>
                 Large size
               </li>
               <li>
                 Less access time.
               </li>
               <li>
                 Less per unit cost.
               </li>
             </ol>  
              <p>Why do we dont have a single memory?</p>
              <p>Since all the three characteristics of an ideal memory is not possible to be present in a single memory so we dont have a single memory.</p>
              <img src="./mm.jpg"/>
              <p>We try to attain those ideal mem characteristics using heirarchy of memories using locality of reference.</p>
              <h3>Locality Of Reference.</h3>
               <p>A program is in general executed in a sequential manner so we prefetch the instructions in the locality of current instruction from sec mem to main mem.</p>
               <p>Now criteria can be achieved as large size : <b>SM</b> less cost : <b>SM</b> less access time : <b>MM</b></p>
               <em>So every time it will first search in MM if it is a miss then in sec memory.</em>
               <h3>Duties Of OS</h3>
               <ol>
                 <li>
                   <h4>Address translation from logical address generated by CPU to physical address with which data can be accessed</h4>

                 </li>
                 <li>
                  <h4>How to store data in main memory which we have prefetched from secondary memory.</h4>
                  <p>We can store that data in two ways</p>
                  <ul>
                    <li><h3>Contiguos Memory Allocation</h3>
                         <p>When we store process in MM in continuos fashion.</p>
                         <b>Advantages</b>
                         <ol>
                           <li>
                             Fast Access
                           </li>
                           <li>
                             Address Translation easy.
                           </li>
                         </ol>
                         <b>Disadvantage</b>
                         <p><em>External Fragmentation</em>Sometimes although the total avlbl space > req space but since it is nopt avlbl in contiguos fashion so we cant use it. </p>
                    </li>
                  </ul>
                 </li>
                 <li><h4>How to make sure that user process cant access the memory of any other process?</h4></li>
               </ol>
             </article>
           </section>
            </main>
    </body>
</html>